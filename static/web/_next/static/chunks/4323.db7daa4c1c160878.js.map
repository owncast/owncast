{"version":3,"file":"static/chunks/4323.db7daa4c1c160878.js","mappings":"mGAAA,SAAAA,EAAAC,CAAA,EACA,oBAAAA,EAAAC,IAAA,gBACA,uGAEA,IAAAC,EAAAH,EAAA,yBACAI,EAAA,0CACA,6CACA,oCACA,iCACA,mCACAC,EAAA,6DACA,kEACA,yDACA,uDACA,qDACA,sDACA,qDACA,kDACA,oDACA,kDACA,wBAEA,SAAAC,EAAAC,CAAA,EACA,OAAAA,EAAAC,MAAA,CAAAD,EAAAC,MAAA,CAAAC,MAAA,IAGO,SAAAC,EAAAC,CAAA,EAOP,QANAC,EAAA,QAEAC,EAAAF,EAAAE,UAAA,EAAAF,EAAAG,gBAAA,8BAEAC,EAAA,CAAAJ,EAAAK,eAAA,CAAAL,EAAAM,eAAA,CAAAN,EAAAO,gBAAA,CAAAP,EAAAQ,gBAAA,CACAR,EAAAI,SAAA,4DACAK,EAAA,EAAkBA,EAAAL,EAAAN,MAAA,CAAsBW,IAAAL,CAAA,CAAAK,EAAA,EAAAL,EAAAM,MAAA,CAAAD,IAAA,GANxC,IAQAE,EAAAX,EAAAW,aAAA,CAEAC,EAAAnB,EAAAoB,EAAAnB,CACAoB,MAAAA,GAAAd,EAAAe,cAAA,EACAH,CAAAA,EAAAA,EAAAI,MAAA,CAAAhB,EAAAe,cAAA,GAEAD,KAAAA,GAAAd,EAAAiB,cAAA,EACAJ,CAAAA,EAAAA,EAAAG,MAAA,CAAAhB,EAAAiB,cAAA,GAEA,IAAAC,EAAA,CAAAlB,CAAAA,EAAAmB,OAAA,EAAAC,EAAAA,OAAApB,EAAAmB,OAAA,GACA,GAAAD,EAAA,CAEA,IAAAG,EAAArB,EAAAqB,WAAA,sDACAT,EAAAA,EAAAI,MAAA,qDACAH,EAAAA,EAAAG,MAAA,mCACA,IAAAM,EAAA,4DAA+E,IAC/E,KAAI,CACJ,IAAAD,EAAArB,EAAAqB,WAAA,4BACAT,EAAAA,EAAAI,MAAA,mBACAH,EAAAA,EAAAG,MAAA,0DACA,qDACA,oDACA,IAAAM,EAAA,kDAAqE,IACrE,KACAC,EAAAlC,EAAAuB,GACAY,EAAAnC,EAAAwB,GAGA,SAAAY,EAAAC,CAAA,CAAA9B,CAAA,EACA,IAAA+B,EAAAD,EAAAC,GAAA,IAAA/B,MAAAA,EAAAgC,SAAA,CAGA,GAFAD,GAAA/B,CAAAA,EAAAiC,MAAA,CAAAH,EAAAI,WAAA,IAEAH,GAAAhC,MAAAA,EAAAC,GAAAmC,IAAA,EACA,IAAAC,EAAArC,EAAAC,GAAAqC,MAAA,CACA,GAAAP,EAAAQ,QAAA,IACA,IAAAC,EAAAT,EAAAI,WAAA,GAKA,OAJAK,EAAAH,EACAI,EAAAV,EAAA9B,GACAuC,EAAAH,GAAAK,EAAAX,EAAA9B,IAAA8B,KAAAA,EAAAY,IAAA,IACA1C,CAAAA,EAAA2C,UAAA,KACA,KAMA,IAJAC,EAAAC,EAAAf,EAAA9B,GAGA,OAFAoC,EAAA,GAAAK,EAAAX,EAAA9B,IACA4C,CAAAA,GAAA,IAAAvC,CAAA,EACAuC,CAEA,QACAC,EAAAf,EAAA9B,EACA,CAEA,SAAA6C,EAAAf,CAAA,CAAA9B,CAAA,CAAA8C,CAAA,EACA,GAAAhB,EAAAQ,QAAA,eAGA,IAAAQ,GAAAhB,EAAAiB,KAAA,yBAGA,GAAAjB,EAAAiB,KAAA,iBACA,IAAAC,EAAA,GAKA,GAHAlB,EAAAiB,KAAA,iCAAyDC,CAAAA,EAAA,IACzDlB,EAAAiB,KAAA,kBAA0CC,CAAAA,EAAA,IAC1ClB,EAAAiB,KAAA,YAAoCC,CAAAA,EAAA,IACpCA,EAGA,OADAlB,EAAAmB,GAAA,OACA,QACA,CAEA,IAAAC,EAAA,GAgBA,GAdApB,EAAAiB,KAAA,oBAAAG,CAAAA,EAAA,IAEApB,EAAAiB,KAAA,gBAAAG,CAAAA,EAAA,IAEApB,EAAAiB,KAAA,iBAAAG,CAAAA,EAAA,IAEApB,EAAAiB,KAAA,oCAEAjB,EAAAmB,GAAA,OAEAC,EAAA,IAGApB,EAAAiB,KAAA,kBAAAG,CAAAA,EAAA,IACAA,EAGA,OADApB,EAAAmB,GAAA,OACA,QACA,CACA,GAGAnB,EAAAiB,KAAA,CAAArB,UAEA,KADAI,EAAAqB,OAAA,GAAAC,WAAA,GAAAC,OAAA,OAKArD,EAAAsD,QAAA,CAAAC,SAiCAC,CAAA,CAAAC,CAAA,EACA,YAAAJ,OAAA,CAAAG,EAAAE,MAAA,IAAAN,WAAA,QACAI,EAAAA,EAAAG,MAAA,IAEA,IAAAC,EAAAJ,GAAAA,EAAAtD,MAAA,CACA2D,EAAA,SAiBA,SAAAC,EAAAhC,CAAA,CAAA9B,CAAA,EACA,MAAA8B,EAAAiC,GAAA,IAEA,GADAjC,EAAAkC,QAAA,gBACAlC,EAAAmB,GAAA,OAEA,IADAnB,EAAAmC,IAAA,GACAL,GAAA9B,EAAAiC,GAAA,GACA,OAAAF,CAAA,MACU,GAAA/B,EAAAiB,KAAA,CAAAS,GAEV,OADAxD,EAAAsD,QAAA,CAAAG,EACAI,OACU,GAAA/B,EAAAiB,KAAA,OAEV,OAAAc,OACU,GAAA/B,EAAAiB,KAAA,KAAwB,KAGlC,GADA/C,EAAAsD,QAAA,CAAAY,SA9BAA,EAAAC,CAAA,EACA,gBAAArC,CAAA,CAAA9B,CAAA,EACA,IAAAoE,EAAAvB,EAAAf,EAAA9B,EAAA,IASA,MARA,eAAAoE,IACAtC,KAAAA,EAAAqB,OAAA,GACAnD,EAAAsD,QAAA,CAAAY,EAAAC,EAAA,GACY,KAAArC,EAAAqB,OAAA,KACZgB,EAAA,EAAAnE,EAAAsD,QAAA,CAAAY,EAAAC,EAAA,GACAnE,EAAAsD,QAAA,CAAAQ,IAGAM,CACA,CACA,EAiBA,GACAtC,EAAAqB,OAAA,UAAAU,CACA,QAAA7D,EAAAsD,QAAA,CAAAxB,EAAA9B,EACA,MAAU,GAAA8B,EAAAiB,KAAA,OACV,OAAAc,CAMA,CALU,GAAA/B,EAAAiB,KAAA,MAEV,OAAA1C,CAGA,CADAyB,EAAAmB,GAAA,SACA,GAEAW,EAAA,CACA,GAAAxD,EAAAiE,sBAAA,CACA,OAAAhE,CAEA,CAAAL,EAAAsD,QAAA,CAAAG,CACA,QACAI,CACA,CAEA,OADAC,EAAAQ,QAAA,IACAR,CACA,EA5FAhC,EAAAqB,OAAA,GAAAnD,EAAAsD,QAAA,EACAtD,EAAAsD,QAAA,CAAAxB,EAAA9B,KAJAA,EAAAsD,QAAA,CAAAiB,SAiGAf,CAAA,CAAAC,CAAA,EACA,YAAAJ,OAAA,CAAAG,EAAAE,MAAA,IAAAN,WAAA,QACAI,EAAAA,EAAAG,MAAA,IAEA,IAAAC,EAAAJ,GAAAA,EAAAtD,MAAA,CACA2D,EAAA,SAEA,SAAAC,EAAAhC,CAAA,CAAA9B,CAAA,EACA,MAAA8B,EAAAiC,GAAA,IAEA,GADAjC,EAAAkC,QAAA,YACAlC,EAAAmB,GAAA,OAEA,IADAnB,EAAAmC,IAAA,GACAL,GAAA9B,EAAAiC,GAAA,GACA,OAAAF,CAAA,MACU,GAAA/B,EAAAiB,KAAA,CAAAS,GAEV,OADAxD,EAAAsD,QAAA,CAAAG,EACAI,CAGA,CADA/B,EAAAmB,GAAA,SACA,GAEAW,EAAA,CACA,GAAAxD,EAAAiE,sBAAA,CACA,OAAAhE,CAEA,CAAAL,EAAAsD,QAAA,CAAAG,CACA,QACAI,CACA,CAEA,OADAC,EAAAQ,QAAA,IACAR,CACA,EAhIAhC,EAAAqB,OAAA,GAAAnD,EAAAsD,QAAA,EACAtD,EAAAsD,QAAA,CAAAxB,EAAA9B,GAIA,CAGA,QAAAa,EAAA,EAAoBA,EAAAL,EAAAN,MAAA,CAAsBW,IAC1C,GAAAiB,EAAAiB,KAAA,CAAAvC,CAAA,CAAAK,EAAA,0BAEA,EAAAkC,KAAA,CAAAzC,GAAA,cAEAN,KAAAA,EAAAgC,SAAA,EAAAF,EAAAiB,KAAA,CAAAtB,GACA,WAEAK,EAAAiB,KAAA,CAAApB,IAAAG,EAAAiB,KAAA,CAAAnD,GACA,UAEAkC,EAAAiB,KAAA,CAAAnB,GACA,UAEAE,EAAAiB,KAAA,kBACA,OAEAjB,EAAAiB,KAAA,CAAAtB,GACA,OAAAzB,EAAAgC,SAAA,EAAAhC,SAAAA,EAAAgC,SAAA,CACA,MACA,UADA,EAKAF,EAAAmC,IAAA,GACAnB,EAAA,KAAAzC,CAAA,CAtBA,CAuHA,SAAAmC,EAAAV,CAAA,CAAA9B,CAAA,EACA,KAAAD,MAAAA,EAAAC,GAAAmC,IAAA,EAAAnC,EAAAC,MAAA,CAAAuE,GAAA,GACAxE,EAAAC,MAAA,CAAAwE,IAAA,EAAuBpC,OAAAtC,EAAAC,GAAAqC,MAAA,CAAAP,EAAA4C,UAAA,CACvBvC,KAAA,KACAwC,MAAA,MACA,CASA,SAAAlC,EAAAX,CAAA,CAAA9B,CAAA,EAEA,IADA,IAAA4E,EAAA9C,EAAAI,WAAA,GACAlC,EAAAC,MAAA,CAAAC,MAAA,IAAAH,EAAAC,GAAAqC,MAAA,CAAAuC,GAAA,CACA,GAAA7E,MAAAA,EAAAC,GAAAmC,IAAA,UACAnC,EAAAC,MAAA,CAAAuE,GAAA,EACA,CACA,OAAAzE,EAAAC,GAAAqC,MAAA,EAAAuC,CACA,CA8CA,OACAC,KAAA,SAEAC,WAAA,WACA,OACAxB,SAAAzB,EACA5B,OAAA,EAAkBoC,OAAA,EAAAF,KAAA,KAAAwC,MAAA,MAAmC,CACrD1C,OAAA,EACAD,UAAA,KACA+C,OAAA,GACAtC,OAAA,CACA,CACA,EAEAuC,MAAA,SAAAlD,CAAA,CAAA9B,CAAA,EACA,IAAAiF,EAAAjF,EAAA2C,UAAA,CACAsC,GAAAjF,CAAAA,EAAA2C,UAAA,KACA,IAAAC,EAAAsC,SA7DApD,CAAA,CAAA9B,CAAA,EACA8B,EAAAC,GAAA,KACA/B,EAAAmF,eAAA,IACAnF,EAAAyC,MAAA,KAGA,IAAAG,EAAA5C,EAAAsD,QAAA,CAAAxB,EAAA9B,GACAmD,EAAArB,EAAAqB,OAAA,GAGA,GAAAnD,EAAAmF,eAAA,EAAAhC,KAAAA,EACA,OAAArB,EAAAiB,KAAA,CAAAtB,EAAA,WAAAH,EAAA,WAAAjB,CAAA,CAgBA,GAdA,KAAA+E,IAAA,CAAAjC,IAAAnD,CAAAA,EAAAmF,eAAA,KAEAvC,CAAAA,YAAAA,GAAAA,WAAAA,CAAA,GACA5C,QAAAA,EAAAgC,SAAA,EACAY,CAAAA,EAAA,QAGAO,CAAAA,QAAAA,GAAAA,UAAAA,CAAA,GACAnD,CAAAA,EAAAyC,MAAA,KAEA,UAAAU,GAAAnD,CAAAA,EAAA+E,MAAA,KACA,KAAA5B,GAAA,CAAAnD,EAAA+E,MAAA,EAAAhF,MAAAA,EAAAC,GAAAmC,IAAA,EAAAL,EAAAiB,KAAA,oBACAP,EAAAV,EAAA9B,GAEAmD,GAAAA,EAAAjD,MAAA,oBAAAkF,IAAA,CAAAxC,GAAA,CACA,IAAAyC,EAAA,MAAgChC,OAAA,CAAAF,GAKhC,GAJA,IAAAkC,GACAC,SA9CAxD,CAAA,CAAA9B,CAAA,CAAAmC,CAAA,EACA,IAAAwC,EAAA7C,EAAAiB,KAAA,uBAAsC,SAAAjB,EAAAyD,MAAA,KACtCvF,EAAAC,MAAA,CAAAwE,IAAA,EAAuBpC,OAAArC,EAAAiC,MAAA,CAAAlB,CAAAA,GAAAe,EAAA4C,UAAA,EACvBvC,KAAAA,EACAwC,MAAAA,CAAA,EACA,EAyCA7C,EAAA9B,EAAA,MAA4CwF,KAAA,CAAAH,EAAAA,EAAA,IAG5CA,IADAA,CAAAA,EAAA,MAA4BhC,OAAA,CAAAF,EAAA,EAC5B,CACA,GAAApD,EAAAC,GAAAmC,IAAA,EAAAgB,EACA,OAAA9C,CAAA,CADAL,EAAAiC,MAAA,CAAAjC,EAAAC,MAAA,CAAAuE,GAAA,GAAAnC,MAAA,CAAAtB,CAAAA,GAAAe,EAAA4C,UAAA,CAEA,EACA,OACA1E,EAAAyC,MAAA,EAAAX,EAAAiC,GAAA,IAAAhE,MAAAA,EAAAC,GAAAmC,IAAA,EAAAnC,EAAAC,MAAA,CAAAC,MAAA,IACAF,EAAAC,MAAA,CAAAuE,GAAA,GAEA5B,CACA,EAmBAd,EAAA9B,GAQA,OANA4C,GAAAA,WAAAA,GACA5C,CAAAA,EAAAgC,SAAA,YAAAY,GAAAA,eAAAA,EAAAd,EAAAqB,OAAA,GAAAP,CAAA,EACA,eAAAA,GAAAA,CAAAA,EAAA,MAEAd,EAAAiC,GAAA,IAAA/D,EAAA+E,MAAA,EACA/E,CAAAA,EAAA+E,MAAA,KACAE,EAAA5E,EAAAuC,CAAA,EAGAX,OAAA,SAAAjC,CAAA,CAAAyF,CAAA,CAAAC,CAAA,EACA,GAAA1F,EAAAsD,QAAA,EAAAzB,EACA,OAAA7B,EAAAsD,QAAA,CAAAgB,QAAA,QAEA,IAAAqB,EAAA5F,EAAAC,GACA4F,EAAAD,EAAAxD,IAAA,EAAAsD,EAAA/B,MAAA,KACAiC,MAAAA,EAAAxD,IAAA,GAAAnC,EAAAyC,MAAA,oCAAA2C,IAAA,CAAAK,UACA,MAAAE,EAAAhB,KAAA,CACAgB,EAAAhB,KAAA,CAAAiB,CAAAA,EAAA,KAEAD,EAAAtD,MAAA,CAAAuD,CAAAA,EAAA7E,GAAA2E,EAAAG,IAAA,KAGAC,aAAA,CACAC,aAAAlG,EAAAuB,MAAA,CAAAtB,GAAAsB,MAAA,mBACA4E,cAAA,+CACAC,cAAA,CAAsBC,KAAA,KACtBC,cAAA,CAAsBC,SAAA,aAAuB,qBAC7C,CACA,CACA,CAIO,IAAAC,EAAAlG,EAAA,IAEAmG,EAAAnG,EAAA,CACPgB,eAL4BoF,6HAAAC,KAAA,KAQ5B","sources":["webpack://_N_E/./node_modules/@codemirror/legacy-modes/mode/python.js","webpack://_N_E/<anon>"],"sourcesContent":["function wordRegexp(words) {\n  return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n}\n\nvar wordOperators = wordRegexp([\"and\", \"or\", \"not\", \"is\"]);\nvar commonKeywords = [\"as\", \"assert\", \"break\", \"class\", \"continue\",\n                      \"def\", \"del\", \"elif\", \"else\", \"except\", \"finally\",\n                      \"for\", \"from\", \"global\", \"if\", \"import\",\n                      \"lambda\", \"pass\", \"raise\", \"return\",\n                      \"try\", \"while\", \"with\", \"yield\", \"in\"];\nvar commonBuiltins = [\"abs\", \"all\", \"any\", \"bin\", \"bool\", \"bytearray\", \"callable\", \"chr\",\n                      \"classmethod\", \"compile\", \"complex\", \"delattr\", \"dict\", \"dir\", \"divmod\",\n                      \"enumerate\", \"eval\", \"filter\", \"float\", \"format\", \"frozenset\",\n                      \"getattr\", \"globals\", \"hasattr\", \"hash\", \"help\", \"hex\", \"id\",\n                      \"input\", \"int\", \"isinstance\", \"issubclass\", \"iter\", \"len\",\n                      \"list\", \"locals\", \"map\", \"max\", \"memoryview\", \"min\", \"next\",\n                      \"object\", \"oct\", \"open\", \"ord\", \"pow\", \"property\", \"range\",\n                      \"repr\", \"reversed\", \"round\", \"set\", \"setattr\", \"slice\",\n                      \"sorted\", \"staticmethod\", \"str\", \"sum\", \"super\", \"tuple\",\n                      \"type\", \"vars\", \"zip\", \"__import__\", \"NotImplemented\",\n                      \"Ellipsis\", \"__debug__\"];\n\nfunction top(state) {\n  return state.scopes[state.scopes.length - 1];\n}\n\nexport function mkPython(parserConf) {\n  var ERRORCLASS = \"error\";\n\n  var delimiters = parserConf.delimiters || parserConf.singleDelimiters || /^[\\(\\)\\[\\]\\{\\}@,:`=;\\.\\\\]/;\n  //               (Backwards-compatibility with old, cumbersome config system)\n  var operators = [parserConf.singleOperators, parserConf.doubleOperators, parserConf.doubleDelimiters, parserConf.tripleDelimiters,\n                   parserConf.operators || /^([-+*/%\\/&|^]=?|[<>=]+|\\/\\/=?|\\*\\*=?|!=|[~!@]|\\.\\.\\.)/]\n  for (var i = 0; i < operators.length; i++) if (!operators[i]) operators.splice(i--, 1)\n\n  var hangingIndent = parserConf.hangingIndent;\n\n  var myKeywords = commonKeywords, myBuiltins = commonBuiltins;\n  if (parserConf.extra_keywords != undefined)\n    myKeywords = myKeywords.concat(parserConf.extra_keywords);\n\n  if (parserConf.extra_builtins != undefined)\n    myBuiltins = myBuiltins.concat(parserConf.extra_builtins);\n\n  var py3 = !(parserConf.version && Number(parserConf.version) < 3)\n  if (py3) {\n    // since http://legacy.python.org/dev/peps/pep-0465/ @ is also an operator\n    var identifiers = parserConf.identifiers|| /^[_A-Za-z\\u00A1-\\uFFFF][_A-Za-z0-9\\u00A1-\\uFFFF]*/;\n    myKeywords = myKeywords.concat([\"nonlocal\", \"False\", \"True\", \"None\", \"async\", \"await\"]);\n    myBuiltins = myBuiltins.concat([\"ascii\", \"bytes\", \"exec\", \"print\"]);\n    var stringPrefixes = new RegExp(\"^(([rbuf]|(br)|(rb)|(fr)|(rf))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n  } else {\n    var identifiers = parserConf.identifiers|| /^[_A-Za-z][_A-Za-z0-9]*/;\n    myKeywords = myKeywords.concat([\"exec\", \"print\"]);\n    myBuiltins = myBuiltins.concat([\"apply\", \"basestring\", \"buffer\", \"cmp\", \"coerce\", \"execfile\",\n                                    \"file\", \"intern\", \"long\", \"raw_input\", \"reduce\", \"reload\",\n                                    \"unichr\", \"unicode\", \"xrange\", \"False\", \"True\", \"None\"]);\n    var stringPrefixes = new RegExp(\"^(([rubf]|(ur)|(br))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n  }\n  var keywords = wordRegexp(myKeywords);\n  var builtins = wordRegexp(myBuiltins);\n\n  // tokenizers\n  function tokenBase(stream, state) {\n    var sol = stream.sol() && state.lastToken != \"\\\\\"\n    if (sol) state.indent = stream.indentation()\n    // Handle scope changes\n    if (sol && top(state).type == \"py\") {\n      var scopeOffset = top(state).offset;\n      if (stream.eatSpace()) {\n        var lineOffset = stream.indentation();\n        if (lineOffset > scopeOffset)\n          pushPyScope(stream, state);\n        else if (lineOffset < scopeOffset && dedent(stream, state) && stream.peek() != \"#\")\n          state.errorToken = true;\n        return null;\n      } else {\n        var style = tokenBaseInner(stream, state);\n        if (scopeOffset > 0 && dedent(stream, state))\n          style += \" \" + ERRORCLASS;\n        return style;\n      }\n    }\n    return tokenBaseInner(stream, state);\n  }\n\n  function tokenBaseInner(stream, state, inFormat) {\n    if (stream.eatSpace()) return null;\n\n    // Handle Comments\n    if (!inFormat && stream.match(/^#.*/)) return \"comment\";\n\n    // Handle Number Literals\n    if (stream.match(/^[0-9\\.]/, false)) {\n      var floatLiteral = false;\n      // Floats\n      if (stream.match(/^[\\d_]*\\.\\d+(e[\\+\\-]?\\d+)?/i)) { floatLiteral = true; }\n      if (stream.match(/^[\\d_]+\\.\\d*/)) { floatLiteral = true; }\n      if (stream.match(/^\\.\\d+/)) { floatLiteral = true; }\n      if (floatLiteral) {\n        // Float literals may be \"imaginary\"\n        stream.eat(/J/i);\n        return \"number\";\n      }\n      // Integers\n      var intLiteral = false;\n      // Hex\n      if (stream.match(/^0x[0-9a-f_]+/i)) intLiteral = true;\n      // Binary\n      if (stream.match(/^0b[01_]+/i)) intLiteral = true;\n      // Octal\n      if (stream.match(/^0o[0-7_]+/i)) intLiteral = true;\n      // Decimal\n      if (stream.match(/^[1-9][\\d_]*(e[\\+\\-]?[\\d_]+)?/)) {\n        // Decimal literals may be \"imaginary\"\n        stream.eat(/J/i);\n        // TODO - Can you have imaginary longs?\n        intLiteral = true;\n      }\n      // Zero by itself with no other piece of number.\n      if (stream.match(/^0(?![\\dx])/i)) intLiteral = true;\n      if (intLiteral) {\n        // Integer literals may be \"long\"\n        stream.eat(/L/i);\n        return \"number\";\n      }\n    }\n\n    // Handle Strings\n    if (stream.match(stringPrefixes)) {\n      var isFmtString = stream.current().toLowerCase().indexOf('f') !== -1;\n      if (!isFmtString) {\n        state.tokenize = tokenStringFactory(stream.current(), state.tokenize);\n        return state.tokenize(stream, state);\n      } else {\n        state.tokenize = formatStringFactory(stream.current(), state.tokenize);\n        return state.tokenize(stream, state);\n      }\n    }\n\n    for (var i = 0; i < operators.length; i++)\n      if (stream.match(operators[i])) return \"operator\"\n\n    if (stream.match(delimiters)) return \"punctuation\";\n\n    if (state.lastToken == \".\" && stream.match(identifiers))\n      return \"property\";\n\n    if (stream.match(keywords) || stream.match(wordOperators))\n      return \"keyword\";\n\n    if (stream.match(builtins))\n      return \"builtin\";\n\n    if (stream.match(/^(self|cls)\\b/))\n      return \"self\";\n\n    if (stream.match(identifiers)) {\n      if (state.lastToken == \"def\" || state.lastToken == \"class\")\n        return \"def\";\n      return \"variable\";\n    }\n\n    // Handle non-detected items\n    stream.next();\n    return inFormat ? null :ERRORCLASS;\n  }\n\n  function formatStringFactory(delimiter, tokenOuter) {\n    while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0)\n      delimiter = delimiter.substr(1);\n\n    var singleline = delimiter.length == 1;\n    var OUTCLASS = \"string\";\n\n    function tokenNestedExpr(depth) {\n      return function(stream, state) {\n        var inner = tokenBaseInner(stream, state, true)\n        if (inner == \"punctuation\") {\n          if (stream.current() == \"{\") {\n            state.tokenize = tokenNestedExpr(depth + 1)\n          } else if (stream.current() == \"}\") {\n            if (depth > 1) state.tokenize = tokenNestedExpr(depth - 1)\n            else state.tokenize = tokenString\n          }\n        }\n        return inner\n      }\n    }\n\n    function tokenString(stream, state) {\n      while (!stream.eol()) {\n        stream.eatWhile(/[^'\"\\{\\}\\\\]/);\n        if (stream.eat(\"\\\\\")) {\n          stream.next();\n          if (singleline && stream.eol())\n            return OUTCLASS;\n        } else if (stream.match(delimiter)) {\n          state.tokenize = tokenOuter;\n          return OUTCLASS;\n        } else if (stream.match('{{')) {\n          // ignore {{ in f-str\n          return OUTCLASS;\n        } else if (stream.match('{', false)) {\n          // switch to nested mode\n          state.tokenize = tokenNestedExpr(0)\n          if (stream.current()) return OUTCLASS;\n          else return state.tokenize(stream, state)\n        } else if (stream.match('}}')) {\n          return OUTCLASS;\n        } else if (stream.match('}')) {\n          // single } in f-string is an error\n          return ERRORCLASS;\n        } else {\n          stream.eat(/['\"]/);\n        }\n      }\n      if (singleline) {\n        if (parserConf.singleLineStringErrors)\n          return ERRORCLASS;\n        else\n          state.tokenize = tokenOuter;\n      }\n      return OUTCLASS;\n    }\n    tokenString.isString = true;\n    return tokenString;\n  }\n\n  function tokenStringFactory(delimiter, tokenOuter) {\n    while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0)\n      delimiter = delimiter.substr(1);\n\n    var singleline = delimiter.length == 1;\n    var OUTCLASS = \"string\";\n\n    function tokenString(stream, state) {\n      while (!stream.eol()) {\n        stream.eatWhile(/[^'\"\\\\]/);\n        if (stream.eat(\"\\\\\")) {\n          stream.next();\n          if (singleline && stream.eol())\n            return OUTCLASS;\n        } else if (stream.match(delimiter)) {\n          state.tokenize = tokenOuter;\n          return OUTCLASS;\n        } else {\n          stream.eat(/['\"]/);\n        }\n      }\n      if (singleline) {\n        if (parserConf.singleLineStringErrors)\n          return ERRORCLASS;\n        else\n          state.tokenize = tokenOuter;\n      }\n      return OUTCLASS;\n    }\n    tokenString.isString = true;\n    return tokenString;\n  }\n\n  function pushPyScope(stream, state) {\n    while (top(state).type != \"py\") state.scopes.pop()\n    state.scopes.push({offset: top(state).offset + stream.indentUnit,\n                       type: \"py\",\n                       align: null})\n  }\n\n  function pushBracketScope(stream, state, type) {\n    var align = stream.match(/^[\\s\\[\\{\\(]*(?:#|$)/, false) ? null : stream.column() + 1\n    state.scopes.push({offset: state.indent + (hangingIndent || stream.indentUnit),\n                       type: type,\n                       align: align})\n  }\n\n  function dedent(stream, state) {\n    var indented = stream.indentation();\n    while (state.scopes.length > 1 && top(state).offset > indented) {\n      if (top(state).type != \"py\") return true;\n      state.scopes.pop();\n    }\n    return top(state).offset != indented;\n  }\n\n  function tokenLexer(stream, state) {\n    if (stream.sol()) {\n      state.beginningOfLine = true;\n      state.dedent = false;\n    }\n\n    var style = state.tokenize(stream, state);\n    var current = stream.current();\n\n    // Handle decorators\n    if (state.beginningOfLine && current == \"@\")\n      return stream.match(identifiers, false) ? \"meta\" : py3 ? \"operator\" : ERRORCLASS;\n\n    if (/\\S/.test(current)) state.beginningOfLine = false;\n\n    if ((style == \"variable\" || style == \"builtin\")\n        && state.lastToken == \"meta\")\n      style = \"meta\";\n\n    // Handle scope changes.\n    if (current == \"pass\" || current == \"return\")\n      state.dedent = true;\n\n    if (current == \"lambda\") state.lambda = true;\n    if (current == \":\" && !state.lambda && top(state).type == \"py\" && stream.match(/^\\s*(?:#|$)/, false))\n      pushPyScope(stream, state);\n\n    if (current.length == 1 && !/string|comment/.test(style)) {\n      var delimiter_index = \"[({\".indexOf(current);\n      if (delimiter_index != -1)\n        pushBracketScope(stream, state, \"])}\".slice(delimiter_index, delimiter_index+1));\n\n      delimiter_index = \"])}\".indexOf(current);\n      if (delimiter_index != -1) {\n        if (top(state).type == current) state.indent = state.scopes.pop().offset - (hangingIndent || stream.indentUnit)\n        else return ERRORCLASS;\n      }\n    }\n    if (state.dedent && stream.eol() && top(state).type == \"py\" && state.scopes.length > 1)\n      state.scopes.pop();\n\n    return style;\n  }\n\n  return {\n    name: \"python\",\n\n    startState: function() {\n      return {\n        tokenize: tokenBase,\n        scopes: [{offset: 0, type: \"py\", align: null}],\n        indent: 0,\n        lastToken: null,\n        lambda: false,\n        dedent: 0\n      };\n    },\n\n    token: function(stream, state) {\n      var addErr = state.errorToken;\n      if (addErr) state.errorToken = false;\n      var style = tokenLexer(stream, state);\n\n      if (style && style != \"comment\")\n        state.lastToken = (style == \"keyword\" || style == \"punctuation\") ? stream.current() : style;\n      if (style == \"punctuation\") style = null;\n\n      if (stream.eol() && state.lambda)\n        state.lambda = false;\n      return addErr ? ERRORCLASS : style;\n    },\n\n    indent: function(state, textAfter, cx) {\n      if (state.tokenize != tokenBase)\n        return state.tokenize.isString ? null : 0;\n\n      var scope = top(state)\n      var closing = scope.type == textAfter.charAt(0) ||\n          scope.type == \"py\" && !state.dedent && /^(else:|elif |except |finally:)/.test(textAfter)\n      if (scope.align != null)\n        return scope.align - (closing ? 1 : 0)\n      else\n        return scope.offset - (closing ? hangingIndent || cx.unit : 0)\n    },\n\n    languageData: {\n      autocomplete: commonKeywords.concat(commonBuiltins).concat([\"exec\", \"print\"]),\n      indentOnInput: /^\\s*([\\}\\]\\)]|else:|elif |except |finally:)$/,\n      commentTokens: {line: \"#\"},\n      closeBrackets: {brackets: [\"(\", \"[\", \"{\", \"'\", '\"', \"'''\", '\"\"\"']}\n    }\n  };\n};\n\nvar words = function(str) { return str.split(\" \"); };\n\nexport const python = mkPython({})\n\nexport const cython = mkPython({\n  extra_keywords: words(\"by cdef cimport cpdef ctypedef enum except \"+\n                        \"extern gil include nogil property public \"+\n                        \"readonly struct union DEF IF ELIF ELSE\")\n})\n"],"names":["wordRegexp","words","join","wordOperators","commonKeywords","commonBuiltins","top","state","scopes","length","mkPython","parserConf","ERRORCLASS","delimiters","singleDelimiters","operators","singleOperators","doubleOperators","doubleDelimiters","tripleDelimiters","i","splice","hangingIndent","myKeywords","myBuiltins","undefined","extra_keywords","concat","extra_builtins","py3","version","Number","identifiers","stringPrefixes","keywords","builtins","tokenBase","stream","sol","lastToken","indent","indentation","type","scopeOffset","offset","eatSpace","lineOffset","pushPyScope","dedent","peek","errorToken","style","tokenBaseInner","inFormat","match","floatLiteral","eat","intLiteral","current","toLowerCase","indexOf","tokenize","formatStringFactory","delimiter","tokenOuter","charAt","substr","singleline","OUTCLASS","tokenString","eol","eatWhile","next","tokenNestedExpr","depth","inner","singleLineStringErrors","isString","tokenStringFactory","pop","push","indentUnit","align","indented","name","startState","lambda","token","addErr","tokenLexer","beginningOfLine","test","delimiter_index","pushBracketScope","column","slice","textAfter","cx","scope","closing","unit","languageData","autocomplete","indentOnInput","commentTokens","line","closeBrackets","brackets","python","cython","str","split"],"sourceRoot":""}